{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MY project**"
      ],
      "metadata": {
        "id": "H-ltORFP-RcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q \"openvino>=2023.1.0\"\n",
        "\n",
        "%pip install -q \"paddlepaddle>=2.5.1\" \"paddle2onnx>=0.6\"\n",
        "%pip install -q \"git+https://github.com/PaddlePaddle/PaddleGAN.git\" --no-deps\n",
        "\n",
        "%pip install -q opencv-python matplotlib scikit-learn scikit-image\n",
        "%pip install -q \"imageio==2.9.0\" \"imageio-ffmpeg\" \"numba>=0.53.1\" easydict munch natsort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3YJRj1607hI",
        "outputId": "a75661f0-8926-4210-a943-22e034f9d408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ppgan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ppgan 2.1.0 requires librosa==0.8.1, but you have librosa 0.10.1 which is incompatible.\n",
            "ppgan 2.1.0 requires opencv-python<=4.6.0.66, but you have opencv-python 4.8.0.76 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = \"model\"\n",
        "MODEL_NAME = \"paddlegan_anime\"\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Create filenames of the models that will be converted in this notebook.\n",
        "model_path = Path(f\"{MODEL_DIR}/{MODEL_NAME}\")\n",
        "ir_path = model_path.with_suffix(\".xml\")\n",
        "onnx_path = model_path.with_suffix(\".onnx\")"
      ],
      "metadata": {
        "id": "Ln7z31G79Ljg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_to_max_width(image, max_width):\n",
        "    \"\"\"\n",
        "    Resize image to max_width, preserving the aspect ratio of the image.\n",
        "    \"\"\"\n",
        "    if image.shape[1] > max_width:\n",
        "        hw_ratio = image.shape[0] / image.shape[1]\n",
        "        new_height = int(max_width * hw_ratio)\n",
        "        image = cv2.resize(image, (max_width, new_height))\n",
        "    return image"
      ],
      "metadata": {
        "id": "4NiYGaan9Lls"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell will initialize the AnimeGANPredictor() and download the weights from PaddlePaddle.\n",
        "# This may take a while. The weights are stored in a cache and are downloaded once.\n",
        "predictor = AnimeGANPredictor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1slxqYSs9Ln2",
        "outputId": "cb6c6fc9-9305-4147-f4ef-93ebde3b5df5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/10 10:02:10] ppgan INFO: Found /root/.cache/ppgan/animeganv2_hayao.pdparams\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In a Jupyter Notebook, ?? shows the source and docstring\n",
        "predictor.run??"
      ],
      "metadata": {
        "id": "qKwesjpw9Lqc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PADDLEGAN_INFERENCE = True\n",
        "OUTPUT_DIR = \"output\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "# Step 1. Load the image and convert to RGB.\n",
        "image_path = Path(\"/content/child-children-girl-happy.webp\")\n",
        "image_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "image = cv2.cvtColor(cv2.imread(str(image_path), flags=cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "## Inference takes a long time on large images. Resize to a max width of 600.\n",
        "image = resize_to_max_width(image, 600)\n",
        "\n",
        "# Step 2. Transform the image.\n",
        "transformed_image = predictor.transform(image)\n",
        "input_tensor = paddle.to_tensor(transformed_image[None, ::])\n",
        "\n",
        "if PADDLEGAN_INFERENCE:\n",
        "    # Step 3. Do inference.\n",
        "    predictor.generator.eval()\n",
        "    with paddle.no_grad():\n",
        "        result = predictor.generator(input_tensor)\n",
        "\n",
        "    # Step 4. Convert the inference result to an image, following the same steps as\n",
        "    # PaddleGAN's predictor.run() function.\n",
        "    result_image_pg = (result * 0.5 + 0.5)[0].numpy() * 255\n",
        "    result_image_pg = result_image_pg.transpose((1, 2, 0))\n",
        "\n",
        "    # Step 5. Resize the result image.\n",
        "    result_image_pg = cv2.resize(result_image_pg, image.shape[:2][::-1])\n",
        "\n",
        "    # Step 6. Adjust the brightness.\n",
        "    result_image_pg = predictor.adjust_brightness(result_image_pg, image)\n",
        "\n",
        "    # Step 7. Save the result image.\n",
        "    anime_image_path_pg = Path(f\"{OUTPUT_DIR}/{image_path.stem}_anime_pg\").with_suffix(\".jpg\")\n",
        "    if cv2.imwrite(str(anime_image_path_pg), result_image_pg[:, :, (2, 1, 0)]):\n",
        "        print(f\"The anime image was saved to {anime_image_path_pg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkTK4j3M9LtC",
        "outputId": "10f2ebe0-5b52-4e9c-ab80-cdc4d67282f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The anime image was saved to output/child-children-girl-happy_anime_pg.jpg\n"
          ]
        }
      ]
    }
  ]
}